{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.1.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project:face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\" style='color: #be2830'>Build Our Dataset</h2>\n",
    "<h4 align=\"center\">\n",
    "Detect $\\rightarrow$ Cut $\\rightarrow$ Normalize $\\rightarrow$ Resize $\\rightarrow$ Save</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detect face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(frame):\n",
    "   \n",
    "        \n",
    "    detector = cv2.CascadeClassifier(\"xml/frontal_face.xml\")\n",
    "\n",
    "    faces = detector.detectMultiScale(frame,1.2)\n",
    "    \n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_scale(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_faces(image, faces_coord):\n",
    "    faces = []\n",
    "      \n",
    "    for (x, y, w, h) in faces_coord:\n",
    "        \n",
    "        faces.append(image[y: y + h, x : x + w ])\n",
    "         \n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize faces by increasing pixel intensity(brightness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_intensity(images):\n",
    "    images_norm = []\n",
    "    for image in images:\n",
    "        images_norm.append(cv2.equalizeHist(image))\n",
    "    return images_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize\n",
    "\n",
    "#### cv.INTER_AREA for shrinking & cv.INTER_CUBIC for zooming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize1(images,size=(47,62)):\n",
    "    image_resize = []\n",
    "    \n",
    "    for image in images:\n",
    "        img_size = cv2.resize(image,size)\n",
    "        \n",
    "        image_resize.append(img_size)\n",
    "        \n",
    "    return image_resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(images,size=(47,62)):\n",
    "    image_resize = []\n",
    "    \n",
    "    for image in images:\n",
    "        if image.shape < size:\n",
    "            img_size = cv2.resize(image,size,interpolation=cv2.INTER_CUBIC)\n",
    "        else:\n",
    "            img_size = cv2.resize(image,size,interpolation=cv2.INTER_AREA)\n",
    "        image_resize.append(img_size)\n",
    "        \n",
    "    return image_resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_faces(frame, faces_coord):\n",
    "    #gray_frame = gray_scale(frame)\n",
    "    faces = cut_faces(frame, faces_coord)\n",
    "    faces = normalize_intensity(faces)\n",
    "    \n",
    "    faces = resize(faces)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_show(image,title=\"\"):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.imshow(image,cmap=\"Greys_r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(image, coords):\n",
    "    for (x, y, w, h) in coords:\n",
    "        \n",
    "        cv2.rectangle(image, (x , y), (x + w , y + h), (0,0,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "#cv2.namedWindow(\"Face\", cv2.WINDOW_AUTOSIZE)\n",
    "folder = \"user/\"+input('Person:').lower()\n",
    "\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "    \n",
    "    flag_start_capturing = False\n",
    "    sample=1\n",
    "   \n",
    "    cv2.namedWindow(\"Face\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "    while True:\n",
    "        ret,frame = cam.read()\n",
    "        gray = gray_scale(frame)\n",
    "        faces_coord = detect_face(gray)\n",
    "\n",
    "        if len(faces_coord):\n",
    "            faces = normalize_faces(gray,faces_coord)\n",
    "              \n",
    "            cv2.imwrite(folder + '/' + str(sample)+'.jpg',faces[0])\n",
    "            plot_show(faces[0],\"Image saved:\"+str(sample))\n",
    "            clear_output(wait=True)\n",
    "            if flag_start_capturing == True:\n",
    "                sample += 1\n",
    "            \n",
    "        draw_rectangle(frame,faces_coord)\n",
    "        cv2.imshow('Face',frame)\n",
    "        keypress=cv2.waitKey(1)\n",
    "        \n",
    "        if keypress == ord('c'):\n",
    "            \n",
    "            if flag_start_capturing == False:\n",
    "                flag_start_capturing = True\n",
    "            \n",
    "        \n",
    "        if sample >20:\n",
    "            break\n",
    "            \n",
    "        if keypress == ord('q'):\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print (\"This name already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset from sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'user/vineet/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5e6ec806af35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# find all files paths from the folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mnum_generated_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'user/vineet/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from scipy import ndarray\n",
    "\n",
    "# image processing library\n",
    "import skimage as sk\n",
    "from skimage import transform\n",
    "from skimage import util\n",
    "from skimage import io\n",
    "\n",
    "def random_rotation(image_array: ndarray):\n",
    "    # pick a random degree of rotation between 25% on the left and 25% on the right\n",
    "    random_degree = random.uniform(-25, 25)\n",
    "    return sk.transform.rotate(image_array, random_degree)\n",
    "\n",
    "def random_noise(image_array: ndarray):\n",
    "    # add random noise to the image\n",
    "    return sk.util.random_noise(image_array)\n",
    "\n",
    "def horizontal_flip(image_array: ndarray):\n",
    "    # horizontal flip doesn't need skimage, it's easy as flipping the image array of pixels !\n",
    "    return image_array[:, ::-1]\n",
    "\n",
    "# dictionary of the transformations we defined earlier\n",
    "available_transformations = {\n",
    "    'rotate': random_rotation,\n",
    "    'noise': random_noise,\n",
    "    'horizontal_flip': horizontal_flip\n",
    "}\n",
    "\n",
    "folder_path = 'user/vineet/'\n",
    "num_files_desired = 950\n",
    "\n",
    "# find all files paths from the folder\n",
    "images = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "num_generated_files = 0\n",
    "while num_generated_files <= num_files_desired:\n",
    "    # random image from the folder\n",
    "    image_path = random.choice(images)\n",
    "    # read image as an two dimensional array of pixels\n",
    "    image_to_transform = sk.io.imread(image_path)\n",
    "    # random num of transformation to apply\n",
    "    num_transformations_to_apply = random.randint(1, len(available_transformations))\n",
    "\n",
    "    num_transformations = 0\n",
    "    transformed_image = None\n",
    "    while num_transformations <= num_transformations_to_apply:\n",
    "        # random transformation to apply for a single image\n",
    "        key = random.choice(list(available_transformations))\n",
    "        transformed_image = available_transformations[key](image_to_transform)\n",
    "        num_transformations += 1\n",
    "\n",
    "    new_file_path = '%s/augmented_image_%s.jpg' % (folder_path, num_generated_files)\n",
    "\n",
    "    # write image to the disk\n",
    "    io.imsave(new_file_path, transformed_image)\n",
    "    num_generated_files += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset for unknown people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-18-fd204c6b9f2b>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-18-fd204c6b9f2b>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    basepath = \"C:\\Users\\lenovo\\scikit_learn_data\\lfw_home\\lfw_funneled\"\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "### datasets for other class\n",
    "\n",
    "basepath = \"C:\\Users\\lenovo\\scikit_learn_data\\lfw_home\\lfw_funneled\"\n",
    "#C:\\Users\\Vineet\\scikit_learn_data\\lfw_home\n",
    "images = os.listdir(basepath) \n",
    "print (len(images))\n",
    "data = images[:1000]\n",
    "\n",
    "for i,folder in enumerate(data,start=1):\n",
    "    \n",
    "    files=os.listdir(basepath+'\\\\'+folder)\n",
    "    for k,img in enumerate(files,start=1):\n",
    "        if img.endswith('.jpg'):\n",
    "            #print img\n",
    "            frame=cv2.imread(basepath+'\\\\'+folder+'\\\\'+img,0)\n",
    "        #print frame\n",
    "       \n",
    "            faces_coord = detect_face(frame)\n",
    "            if len(faces_coord):\n",
    "                faces = cut_faces(frame, faces_coord)\n",
    "                #print faces\n",
    "                faces = normalize_intensity(faces)\n",
    "                faces = resize(faces)\n",
    "                cv2.imwrite('user/unknown/' + str(i)+'.jpg',faces[0])\n",
    "                \n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_dataset():\n",
    "    images = []\n",
    "    labels = []\n",
    "    labels_dic = {}\n",
    "   \n",
    "    people = [person for person in os.listdir(\"user/\")]\n",
    "   \n",
    "    for i, person in enumerate(people):\n",
    "        labels_dic[i] = person\n",
    "        for image in os.listdir(\"user/\" + person):\n",
    "            if image.endswith('.jpg'):\n",
    "                images.append(cv2.imread(\"user/\" + person + '/' + image, 0))\n",
    "                labels.append(i)\n",
    "    return (images, np.array(labels), labels_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, labels_dic = collect_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409\n",
      "{0: 'ankit yadav', 1: 'suhani', 2: 'unknown'}\n"
     ]
    }
   ],
   "source": [
    "print (len(images))\n",
    "print (labels_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1, 408], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 47)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(409, 62, 47)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=X_train.reshape(len(X_train),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(409, 2914)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(train.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components=.97)\n",
    "new_train=pca1.fit_transform(X_train_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV,KFold\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param = {'C':[.001,.01,.1,1,10],'penalty':['l2','l1']}\n",
    "param = {\"penalty\": [\"none\", \"l1\", \"l2\"],\n",
    "         'eta0':[.001,.01,.1,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd = GridSearchCV(SGDClassifier(max_iter=2000,loss='log',early_stopping=True),\n",
    "                  param_grid=param,cv=5,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gd.fit(new_train,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = gd.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sgd_face.pkl'\n",
    "f=open(filename, 'wb')\n",
    "pickle.dump(clf2,f)\n",
    " \n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sgd_face.pkl'\n",
    "\n",
    "\n",
    "svc1= pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=True, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=2000,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankit Yadav\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Ankit Yadav\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1 class",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-dbcba225cb47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    685\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    664\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 666\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    711\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m                          sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self.max_iter,\n\u001b[1;32m--> 554\u001b[1;33m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0m\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         if (self.tol is not None and self.tol > -np.inf\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    516\u001b[0m             raise ValueError(\n\u001b[0;32m    517\u001b[0m                 \u001b[1;34m\"The number of classes has to be greater than one;\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m                 \" got %d class\" % n_classes)\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
     ]
    }
   ],
   "source": [
    "gd.fit(new_train,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290.93771887]\n",
      "[[0. 1.]]\n",
      "[1] 1\n",
      "Vineet\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "font=cv2.FONT_HERSHEY_PLAIN\n",
    "cv2.namedWindow(\"opencv_face\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret,frame = cam.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces_coord = detect_face(gray) # detect more than one face\n",
    "    if len(faces_coord):\n",
    "        faces = normalize_faces(gray, faces_coord)\n",
    "        #faces = normalize_intensity(faces)\n",
    "        for i, face in enumerate(faces): # for each detected face\n",
    "            \n",
    "            \n",
    "            #cv2.imwrite('trainingData/female/picture_BGR5.jpg',face)\n",
    "            t=face.reshape(1,-1)\n",
    "            t=sc.transform(t.astype(np.float64))\n",
    "            test = pca1.transform(t)    \n",
    "            #print test\n",
    "            #transform = test.reshape(1,-1)\n",
    "            #print transform\n",
    "            prob=svc1.predict_proba(test)\n",
    "            confidence = svc1.decision_function(test)\n",
    "            print (confidence)\n",
    "            print (prob)\n",
    "           \n",
    "            \n",
    "            \n",
    "            pred = svc1.predict(test)\n",
    "            print (pred,pred[0])\n",
    "           \n",
    "            name=labels_dic[pred[0]].capitalize()\n",
    "            print (name)\n",
    "           \n",
    "           \n",
    "            if prob[0][1]>.9:\n",
    "                \n",
    "                cv2.putText(frame, 'vineet',(faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 2, (66, 53, 243), 2)\n",
    "            \n",
    "                \n",
    "            elif prob[0][0]>.9:\n",
    "                cv2.putText(frame,'unknown',(faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 3, (66, 53, 243), 2)\n",
    "                \n",
    "                \n",
    "           \n",
    "        clear_output(wait = True)\n",
    "        draw_rectangle(frame, faces_coord) # rectangle around face\n",
    "        \n",
    "    cv2.putText(frame, \"ESC to exit\", (5, frame.shape[0] - 5),cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2,cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow(\"opencv_face\", frame) # live feed in external\n",
    "    if cv2.waitKey(5) == 27:\n",
    "        break\n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
